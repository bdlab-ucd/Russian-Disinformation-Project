{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_embed = np.load(\"anger_resnet50_image_embeddings.npz\")\n",
    "\n",
    "img_embed.files\n",
    "img_embed['arr_3011'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embed = np.load(\"bert_word_embeddings.npz\")\n",
    "\n",
    "word_embed.files\n",
    "word_embed['arr_3011'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2816,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((word_embed['arr_0'], img_embed['arr_0']), axis=None).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "for i in range(0, 3012):\n",
    "    key_str = 'arr_' + str(i)\n",
    "    data.append(np.concatenate((word_embed[key_str], img_embed[key_str]), axis=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "# matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Nadam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import logcosh, binary_crossentropy\n",
    "from keras.activations import relu, elu, sigmoid\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# import matplotlib\n",
    "# matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 300\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = []\n",
    "\n",
    "df_items = pd.read_csv('items-Copy1.csv') # read dataset into pandas dataframe\n",
    "\n",
    "# replace field that's entirely space (or empty) with NaN\n",
    "df_items = df_items.replace(np.nan, '', regex=True)\n",
    "\n",
    "# binary classification so either anger or not\n",
    "for i, row in df_items.iterrows():\n",
    "    row['tag'] = row['tag'].lower() # convert tags to lowercase\n",
    "    if 'anger' in row['tag']:\n",
    "        labels.append('anger')\n",
    "    else:\n",
    "        labels.append('non_anger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] done compiling.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1024)              2884608   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,409,921\n",
      "Trainable params: 3,409,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(1024, activation='relu', input_shape=(2816,)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "    metrics=[\"accuracy\"])\n",
    "print(\"[INFO] done compiling.\")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(trainX)\n",
    "rescaledX_test = scaler.fit_transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Train on 2288 samples, validate on 121 samples\n",
      "Epoch 1/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.3347 - accuracy: 0.9008 - val_loss: 0.3326 - val_accuracy: 0.8264\n",
      "Epoch 2/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.2795 - accuracy: 0.8671 - val_loss: 0.2245 - val_accuracy: 0.9008\n",
      "Epoch 3/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.1984 - accuracy: 0.9104 - val_loss: 0.1607 - val_accuracy: 0.9174\n",
      "Epoch 4/100\n",
      "2288/2288 [==============================] - 0s 62us/step - loss: 0.1504 - accuracy: 0.9353 - val_loss: 0.1459 - val_accuracy: 0.9421\n",
      "Epoch 5/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.1189 - accuracy: 0.9489 - val_loss: 0.1229 - val_accuracy: 0.9339\n",
      "Epoch 6/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.1065 - accuracy: 0.9563 - val_loss: 0.2265 - val_accuracy: 0.9008\n",
      "Epoch 7/100\n",
      "2288/2288 [==============================] - 0s 62us/step - loss: 0.1207 - accuracy: 0.9458 - val_loss: 0.1362 - val_accuracy: 0.9339\n",
      "Epoch 8/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0731 - accuracy: 0.9703 - val_loss: 0.2035 - val_accuracy: 0.9091\n",
      "Epoch 9/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0659 - accuracy: 0.9747 - val_loss: 0.1565 - val_accuracy: 0.9256\n",
      "Epoch 10/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.1013 - accuracy: 0.9567 - val_loss: 0.2554 - val_accuracy: 0.9091\n",
      "Epoch 11/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0541 - accuracy: 0.9790 - val_loss: 0.1604 - val_accuracy: 0.9339\n",
      "Epoch 12/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0424 - accuracy: 0.9873 - val_loss: 0.2228 - val_accuracy: 0.9091\n",
      "Epoch 13/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0740 - accuracy: 0.9707 - val_loss: 0.1509 - val_accuracy: 0.9421\n",
      "Epoch 14/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.1164 - accuracy: 0.9524 - val_loss: 0.1704 - val_accuracy: 0.9174\n",
      "Epoch 15/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0653 - accuracy: 0.9768 - val_loss: 0.1989 - val_accuracy: 0.9339\n",
      "Epoch 16/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0602 - accuracy: 0.9781 - val_loss: 0.1914 - val_accuracy: 0.9174\n",
      "Epoch 17/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.1851 - val_accuracy: 0.9421\n",
      "Epoch 18/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0400 - accuracy: 0.9865 - val_loss: 0.2811 - val_accuracy: 0.8843\n",
      "Epoch 19/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0602 - accuracy: 0.9799 - val_loss: 0.3612 - val_accuracy: 0.8926\n",
      "Epoch 20/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0522 - accuracy: 0.9812 - val_loss: 0.2243 - val_accuracy: 0.8926\n",
      "Epoch 21/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0411 - accuracy: 0.9851 - val_loss: 0.2759 - val_accuracy: 0.8926\n",
      "Epoch 22/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0442 - accuracy: 0.9851 - val_loss: 0.5240 - val_accuracy: 0.8430\n",
      "Epoch 23/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0448 - accuracy: 0.9830 - val_loss: 0.2265 - val_accuracy: 0.9256\n",
      "Epoch 24/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0292 - accuracy: 0.9917 - val_loss: 0.2160 - val_accuracy: 0.9174\n",
      "Epoch 25/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.3232 - val_accuracy: 0.9174\n",
      "Epoch 26/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0277 - accuracy: 0.9886 - val_loss: 0.3366 - val_accuracy: 0.9174\n",
      "Epoch 27/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0364 - accuracy: 0.9873 - val_loss: 0.3029 - val_accuracy: 0.9091\n",
      "Epoch 28/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0209 - accuracy: 0.9917 - val_loss: 0.2724 - val_accuracy: 0.9256\n",
      "Epoch 29/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.4217 - val_accuracy: 0.8595\n",
      "Epoch 30/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0361 - accuracy: 0.9878 - val_loss: 0.2921 - val_accuracy: 0.9256\n",
      "Epoch 31/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0673 - accuracy: 0.9716 - val_loss: 0.2694 - val_accuracy: 0.9008\n",
      "Epoch 32/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0331 - accuracy: 0.9895 - val_loss: 0.2517 - val_accuracy: 0.9256\n",
      "Epoch 33/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0507 - accuracy: 0.9830 - val_loss: 1.4447 - val_accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.5370 - accuracy: 0.8103 - val_loss: 0.3932 - val_accuracy: 0.8430\n",
      "Epoch 35/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.1656 - accuracy: 0.9296 - val_loss: 0.2992 - val_accuracy: 0.9008\n",
      "Epoch 36/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0908 - accuracy: 0.9663 - val_loss: 0.2729 - val_accuracy: 0.9008\n",
      "Epoch 37/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0678 - accuracy: 0.9764 - val_loss: 0.3044 - val_accuracy: 0.9174\n",
      "Epoch 38/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.1178 - accuracy: 0.9484 - val_loss: 0.2646 - val_accuracy: 0.9008\n",
      "Epoch 39/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.2893 - val_accuracy: 0.8926\n",
      "Epoch 40/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.2653 - val_accuracy: 0.8760\n",
      "Epoch 41/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.2520 - val_accuracy: 0.8926\n",
      "Epoch 42/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.2403 - val_accuracy: 0.9174\n",
      "Epoch 43/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0257 - accuracy: 0.9934 - val_loss: 0.2556 - val_accuracy: 0.8926\n",
      "Epoch 44/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 0.2902 - val_accuracy: 0.9091\n",
      "Epoch 45/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0255 - accuracy: 0.9926 - val_loss: 0.2578 - val_accuracy: 0.9008\n",
      "Epoch 46/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.1146 - accuracy: 0.9580 - val_loss: 0.3593 - val_accuracy: 0.8843\n",
      "Epoch 47/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.1536 - accuracy: 0.9375 - val_loss: 0.5371 - val_accuracy: 0.8264\n",
      "Epoch 48/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0702 - accuracy: 0.9755 - val_loss: 0.3555 - val_accuracy: 0.8512\n",
      "Epoch 49/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0352 - accuracy: 0.9904 - val_loss: 0.2744 - val_accuracy: 0.8843\n",
      "Epoch 50/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 0.2716 - val_accuracy: 0.9174\n",
      "Epoch 51/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 0.2324 - val_accuracy: 0.9091\n",
      "Epoch 52/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.2808 - val_accuracy: 0.8678\n",
      "Epoch 53/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.2871 - val_accuracy: 0.9091\n",
      "Epoch 54/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.2610 - val_accuracy: 0.9008\n",
      "Epoch 55/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.2583 - val_accuracy: 0.9008\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.3169 - val_accuracy: 0.8843\n",
      "Epoch 57/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.2772 - val_accuracy: 0.9091\n",
      "Epoch 58/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.2719 - val_accuracy: 0.9091\n",
      "Epoch 59/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0216 - accuracy: 0.9926 - val_loss: 0.2925 - val_accuracy: 0.9091\n",
      "Epoch 60/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 0.2802 - val_accuracy: 0.9008\n",
      "Epoch 61/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.4991 - val_accuracy: 0.8760\n",
      "Epoch 62/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.3207 - val_accuracy: 0.8926\n",
      "Epoch 63/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.3602 - val_accuracy: 0.9008\n",
      "Epoch 64/100\n",
      "2288/2288 [==============================] - 0s 59us/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.2560 - val_accuracy: 0.8926\n",
      "Epoch 65/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.3559 - val_accuracy: 0.8926\n",
      "Epoch 66/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.3307 - val_accuracy: 0.8843\n",
      "Epoch 67/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.3905 - val_accuracy: 0.9091\n",
      "Epoch 68/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.5337 - val_accuracy: 0.8678\n",
      "Epoch 69/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0433 - accuracy: 0.9851 - val_loss: 0.3811 - val_accuracy: 0.8760\n",
      "Epoch 70/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.1385 - accuracy: 0.9545 - val_loss: 0.5782 - val_accuracy: 0.8512\n",
      "Epoch 71/100\n",
      "2288/2288 [==============================] - 0s 60us/step - loss: 0.0300 - accuracy: 0.9891 - val_loss: 0.3278 - val_accuracy: 0.9091\n",
      "Epoch 72/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0195 - accuracy: 0.9961 - val_loss: 0.3348 - val_accuracy: 0.9091\n",
      "Epoch 73/100\n",
      "2288/2288 [==============================] - 0s 61us/step - loss: 0.0294 - accuracy: 0.9904 - val_loss: 0.5952 - val_accuracy: 0.8512\n",
      "Epoch 74/100\n",
      "  64/2288 [..............................] - ETA: 0s - loss: 0.0204 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "# H = model.fit_generator(\n",
    "#     aug.flow(trainX, trainY, batch_size=BS),\n",
    "#     validation_data=(testX, testY),\n",
    "#     steps_per_epoch=len(trainX) // BS,\n",
    "#     epochs=EPOCHS, verbose=1)#, class_weight={0:3, 1:1})\n",
    "model.fit(np.array(rescaledX_train), np.array(trainY), epochs=100, batch_size=64, validation_split=0.2)\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save(\"anger_imbalanced_fusion_embeddings_fully_connected.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs = model.predict(np.array(rescaledX_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_classes = np.argmax(yhat_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "---------------------------------------------------------- \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.27      1.00      0.43       165\n",
      "   non-anger       0.00      0.00      0.00       438\n",
      "\n",
      "    accuracy                           0.27       603\n",
      "   macro avg       0.14      0.50      0.21       603\n",
      "weighted avg       0.07      0.27      0.12       603\n",
      "\n",
      "---------------------------------------------------------- \n",
      "Accuracy score: 0.273632\n",
      "Precision score: 0.000000\n",
      "Recall score: 0.000000\n",
      "F1 score: 0.000000\n",
      "---------------------------------------------------------- \n",
      "Confusion matrix: \n",
      "[[165   0]\n",
      " [438   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165   0]\n",
      " [438   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "classif_report = classification_report(testY, yhat_classes, target_names=['anger', 'non-anger'])\n",
    "print('Classification report: ')\n",
    "print('---------------------------------------------------------- ')\n",
    "print(classif_report)\n",
    "\n",
    "print('---------------------------------------------------------- ')\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(testY, yhat_classes)\n",
    "print('Accuracy score: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(testY, yhat_classes)\n",
    "print('Precision score: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(testY, yhat_classes)\n",
    "print('Recall score: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(testY, yhat_classes)\n",
    "print('F1 score: %f' % f1)\n",
    "print('---------------------------------------------------------- ')\n",
    "\n",
    "# confusion matrix\n",
    "labels = ['anger', 'none']\n",
    "matrix = confusion_matrix(testY, yhat_classes)\n",
    "print('Confusion matrix: ')\n",
    "print(matrix)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(matrix)\n",
    "plt.title('Confusion Matrix')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('confusion_matrix_anger_minority_duplicated_resnet50_400_epochs.png')\n",
    "plt.show()\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
